# -*- coding: utf-8 -*-
"""Lenet5_CIFAR10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PDfNpFvitaV3TNwxnuQ1ChBQrpImaCDw
"""

import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np

import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch.backends.cudnn as cudnn
from torch.utils.data.sampler import SubsetRandomSampler
import time

device = 'cuda' if torch.cuda.is_available() else 'cpu'

"""# Preprocess

## Loading dataset  
Pytorch tutorial for CIFAR-10: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html  
Collection of high acc NN for CIFAR-10 https://github.com/kuangliu/pytorch-cifar
"""

from torchvision import datasets

train_data = datasets.CIFAR10('./cifar10_data', train=True, download=True)
# use np.concatenate to stick all the images together to form a 1600000 X 32 X 3 array
x = np.concatenate([np.asarray(train_data[i][0]) for i in range(len(train_data))])
print(x.shape)
train_mean = np.mean(x, axis=(0, 1))
train_std = np.std(x, axis=(0, 1))
print(train_mean / 255, train_std / 255)

# this section is to create train and validate set
transform_train = transforms.Compose([
    transforms.ToTensor(),
    # changed to the computed mean/std 
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))
])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform_train)
num_train = len(trainset)
indices = list(range(num_train))
train_idx, valid_idx = indices[10000:], indices[:10000]
train_sampler = SubsetRandomSampler(train_idx)
valid_sampler = SubsetRandomSampler(valid_idx)

trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, sampler=train_sampler,
                                          num_workers=2)
validloader = torch.utils.data.DataLoader(
    trainset, batch_size=128, sampler=valid_sampler,
    num_workers=2,
)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform_test)
testloader = torch.utils.data.DataLoader(testset, batch_size=128,
                                         shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

"""## CNN
http://colah.github.io/posts/2014-07-Conv-Nets-Modular/  
Docs for `torch.nn`: https://pytorch.org/docs/stable/nn.html#linear  
LeNet 5 : https://ieeexplore.ieee.org/abstract/document/726791  
CIFAR-10 nn plot: https://chahatdeep.github.io/docs/NNvsSVM.pdf
"""


class ConvNet(nn.Module):
    '''Convolutional Neural Network on the 32*32 input grid'''

    def __init__(self, dropout=0, activation='ReLU'):
        super(ConvNet, self).__init__()
        # set the 1st convolutional layer with in_channels=3 out_channels=6 kernel_size=5*5
        self.conv1 = nn.Conv2d(3, 6, 5)
        # set the 2nd convolutional layer within_channels=6 out_channels=16 kernel_size=5*5
        self.conv2 = nn.Conv2d(6, 16, 5)
        # set a max pooling layer to pick up the max value from a selected region
        # height = 2, width = 2
        self.pool = nn.MaxPool2d(2, 2)
        # set 3 layers of fully connected MLP that apply linear transformations to the incoming data
        # input: 16 grids each of which is 5*5, output: 120 units
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        # input: 120 units, output: 84 units
        # 84: represent a stylized image of the corresponding character class drawn on a 7*12 bitmap
        self.fc2 = nn.Linear(120, 84)
        # set the dropout probability
        self.dropout = nn.Dropout(dropout)
        # transform to the 10 classes as output
        self.fc3 = nn.Linear(84, 10)
        self.activation = activation

    def forward(self, x):
        if self.activation == 'ReLU':
            f = F.relu
        elif self.activation == 'sigmoid':
            f = torch.sigmoid
        elif self.activation == 'tanh':
            f = torch.tanh
        x = self.pool(f(self.conv1(x)))
        x = self.pool(f(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = f(self.fc1(x))
        x = self.dropout(x)
        x = f(self.fc2(x))
        x = self.fc3(x)
        return x


def train(epoch):
    '''Run one epoch, return the train acc and loss'''
    net.train()  # switch to training mode

    print('\nEpoch: %d' % epoch)  # print the current number of epoch
    # initialize several performance indicators
    train_loss = 0
    batch_idx = 0
    correct = 0
    total = 0
    for batch_idx, (inputs, targets) in enumerate(trainloader):
        inputs, targets = inputs.to(device), targets.to(device)  # put the training pairs to gpu if applies
        optimizer.zero_grad()  # clear the current gradient, otherwise it will accumulate
        outputs = net(inputs)  # compute the outputs
        loss = criterion(outputs,
                         targets)  # calculate the loss function based on the criterion defined outside of the function
        loss.backward()  # computes dloss/dx for every parameter x
        optimizer.step()  # update the parameter based on the current gradient

        train_loss += loss.item()  # extracts the lossâ€™s value as a Python float
        _, predicted = outputs.max(1)  # match the predicted label with the output
        total += targets.size(0)  # counter for the number of instances we've trained
        correct += predicted.eq(targets).sum().item()

    print('Training accuracy : %0.3f %%' % (100 * correct / total))
    return 100 * correct / total, train_loss / (batch_idx + 1)  # return the training acc and training loss per batch


def validate(epoch, lr, best_epoch, dropout=0, activation='ReLU', optimizer='adam', patience=10, stop=False):
    '''Evaluate the model, return the validating acc, loss, epoch number that has the best acc'''
    global cnn_best_acc_valid  # refer to a global variable
    global epochs_no_improve
    global cnn_min_loss
    global cnn_local_best  # the best acc for each net
    net.eval()  # switch to evaluation mode
    test_loss = 0
    batch_idx = 0
    correct = 0
    total = 0
    with torch.no_grad():  # with no_grad() we have higher speeds and can use larger batch size (100)
        for batch_idx, (inputs, targets) in enumerate(validloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            loss = criterion(outputs, targets)

            test_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

    print('Validation accuracy : %0.3f %%' % (100 * correct / total))

    # Save the model with the largest test acc
    acc = 100. * correct / total
    if acc > cnn_best_acc_valid:
        print('Saving..')
        state = {
            'net': net.state_dict(),
            'acc': acc,
            'epoch': epoch,
            'lr': lr,
            'dropout': dropout,
            'activation': activation,
            'optimizer': optimizer,
        }
        torch.save(state, 'bestCNN_valid.pth')
        cnn_best_acc_valid = acc
    # if the current acc is larger than this model's best acc, update the epoch which has the best acc
    # if test_loss < cnn_local_best:
    #  best_epoch = epoch
    # Early stopping based on the loss
    # if the test loss is decreasing in 'patience' consecutive times, return the signal to break
    if test_loss < cnn_min_loss:
        epochs_no_improve = 0
        cnn_min_loss = test_loss
        best_epoch = epoch
    else:
        epochs_no_improve += 1
    if epochs_no_improve == patience:
        print('Early stopping!')
        stop = True

    return 100 * correct / total, test_loss / (batch_idx + 1), best_epoch, stop  # return the test acc for current model


"""# Training

## Tuning the activation function using validation set
reason that the validation acc is higher at first:https://stackoverflow.com/questions/50422872/validation-and-training-accuracy-high-in-the-first-epoch-keras
"""

net = ConvNet()
# Define a Loss function
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)
cnn_best_acc_valid = 0
epochs_no_improve = 0
cnn_min_loss = np.Inf
cnn_local_best = np.Inf


def tuningActivation(maxepoch, lr, activations, dropout=0):
    '''
    activation = ['ReLU','sigmoid','tanh']
    optimizer = []
    '''
    colors = ['r', 'b', 'g', 'c', 'b']
    global cnn_min_loss
    global epochs_no_improve
    global cnn_local_best
    for activation, color in zip(activations, colors):
        global net
        global optimizer
        cnn_min_loss = np.Inf
        epochs_no_improve = 0
        cnn_local_best = 0  # reset the single model's acc to 0 at the start

        net = ConvNet(dropout=dropout, activation=activation)
        net = net.to(device)
        if device == 'cuda':
            net = torch.nn.DataParallel(net)
            cudnn.benchmark = True
        criterion = nn.CrossEntropyLoss()
        epoch_list = list(range(1, maxepoch + 1))
        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)
        valid_acc_list = []
        train_acc_list = []
        train_loss_list = []
        valid_loss_list = []
        best_epoch = 0
        start = time.time()
        for epoch in epoch_list:  # train and validate the model until
            train_acc, train_loss = train(epoch)
            valid_acc, valid_loss, best_epoch, stop = validate(epoch, lr=lr, best_epoch=best_epoch, dropout=dropout,
                                                               activation=activation)
            valid_acc_list.append(valid_acc)
            train_acc_list.append(train_acc)
            train_loss_list.append(train_loss)
            valid_loss_list.append(valid_loss)
            if stop:  # if reach the patience limit, exit the loop
                break

        end = time.time()
        print('Time spent: %0.2f s' % (end - start))
        print('The lowest loss is at epoch ' + str(best_epoch))

        # plot results
        plt.plot(epoch_list[:len(train_loss_list)], train_loss_list, '--', color=color, label=activation + " train")
        plt.plot(epoch_list[:len(valid_loss_list)], valid_loss_list, color=color, label=activation + " val")
        plt.plot(best_epoch, min(valid_loss_list), marker='o', color=color, markersize=5)
        print('Activation: {} - lowest validation loss: {}'.format(activation, min(valid_loss_list)))
        print('-' * 100)
    plt.legend()
    plt.title("Loss vs. # of Epochs")
    plt.savefig("cnn_activation.png")


# early stopping after 5 non-decreasing loss in a roll + timer + best epoch marker
activations = ['ReLU', 'sigmoid', 'tanh']
tuningActivation(500, 0.01, activations=activations)

"""## Tuning the optimizer type using validation set"""

net = ConvNet()
# Define a Loss function
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
cnn_best_acc_valid = 0
cnn_min_loss = np.Inf
epochs_no_improve = 0
cnn_local_best = 0


def tuningOptimizer(maxepoch, lr, optimizers, dropout=0):
    '''
    activation = ['ReLU','sigmoid','tanh']
    optimizer = []
    '''
    colors = ['r', 'b', 'g', 'c', 'b']
    global cnn_min_loss
    global epochs_no_improve
    global cnn_local_best
    for opt, color in zip(optimizers, colors):
        global net
        global optimizer
        cnn_min_loss = np.Inf
        epochs_no_improve = 0
        cnn_local_best = 0  # reset the single model's acc to 0 at the start

        net = ConvNet(dropout=dropout, activation='ReLU')
        net = net.to(device)
        if device == 'cuda':
            net = torch.nn.DataParallel(net)
            cudnn.benchmark = True
        criterion = nn.CrossEntropyLoss()
        epoch_list = list(range(1, maxepoch + 1))
        if opt == 'adagrad':
            optimizer = optim.Adagrad(net.parameters(), lr=lr)
        elif opt == 'adam':
            optimizer = optim.Adam(net.parameters(), lr=lr)
        elif opt == 'rmsprop':
            optimizer = optim.RMSprop(net.parameters(), lr=lr)
        elif opt == 'sgd':
            optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)
        valid_acc_list = []
        train_acc_list = []
        train_loss_list = []
        valid_loss_list = []
        best_epoch = 0
        start = time.time()
        for epoch in epoch_list:
            train_acc, train_loss = train(epoch)
            valid_acc, valid_loss, best_epoch, stop = validate(epoch, lr=lr, best_epoch=best_epoch, dropout=dropout,
                                                               optimizer=opt)
            valid_acc_list.append(valid_acc)
            train_acc_list.append(train_acc)
            train_loss_list.append(train_loss)
            valid_loss_list.append(valid_loss)
            if stop:  # if reach the patience limit, exit the loop
                break
        end = time.time()
        print('Time spent: %0.2f s' % (end - start))  # print the time spent for this model(train+validate)
        print('The lowest loss is at epoch ' + str(best_epoch))

        # plot train loss vs epoch
        plt.plot(epoch_list[:len(train_loss_list)], train_loss_list, '--', color=color, label=opt + " train")
        # plot validation loss vs epoch
        plt.plot(epoch_list[:len(valid_loss_list)], valid_loss_list, color=color, label=opt + " val")
        # plot the point which has the lowest loss among all the epochs
        plt.plot(best_epoch, min(valid_loss_list), marker='o', color=color, markersize=5)
        print('Activation: {} - lowest validation loss: {}'.format(opt, min(valid_loss_list)))
        print('-' * 100)
    plt.legend()
    plt.title("Loss vs. Optimizer types")
    plt.savefig("cnn_optimizer.png")


optimizers = ['adagrad', 'adam', 'rmsprop', 'sgd']
tuningOptimizer(500, 0.01, optimizers)

"""## Tuning hyperparameter on validation set
using SGD and ReLU from the previous experiment results
"""

net = ConvNet()
# Define a Loss function
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
cnn_best_acc_valid = 0
epochs_no_improve = 0
cnn_min_loss = np.Inf
cnn_local_best = np.Inf


def tuningParam(maxepoch, lrs, dropouts):
    '''
    lrs: a list containing all lrs we want to test on
    '''
    colors = ['lightcoral', 'maroon', 'red', 'darkgoldenrod', 'darkorange', 'gold', 'cadetblue', 'lightskyblue',
              'steelblue']
    plt.figure(figsize=(12, 10))
    global net
    global optimizer
    global cnn_min_loss
    global cnn_min_loss
    global epochs_no_improve
    global cnn_local_best
    i = 0  # counter for the color
    for lr in lrs:
        for drop, color in zip(dropouts, colors):
            cnn_min_loss = np.Inf
            epochs_no_improve = 0
            cnn_local_best = 0  # reset the single model's acc to 0 at the start
            best_epoch = 0

            net = ConvNet(dropout=drop, activation='ReLU')
            optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)
            net = net.to(device)
            if device == 'cuda':
                net = torch.nn.DataParallel(net)
                cudnn.benchmark = True
            criterion = nn.CrossEntropyLoss()
            epoch_list = list(range(1, maxepoch + 1))
            valid_acc_list = []
            train_acc_list = []
            train_loss_list = []
            valid_loss_list = []
            start = time.time()
            for epoch in epoch_list:  # train and validate the model until
                train_acc, train_loss = train(epoch)
                valid_acc, valid_loss, best_epoch, stop = validate(epoch, lr=lr, best_epoch=best_epoch, dropout=drop,
                                                                   activation='ReLU')
                valid_acc_list.append(valid_acc)
                train_acc_list.append(train_acc)
                train_loss_list.append(train_loss)
                valid_loss_list.append(valid_loss)
                if stop:  # if reach the patience limit, exit the loop
                    break

            # plot results
            end = time.time()
            print('Time spent: %0.2f s' % (end - start))

            plt.plot(epoch_list[:len(train_loss_list)], train_loss_list, '--', color=colors[i],
                     label='lr=' + str(lr) + 'drop=' + str(drop) + "--train")
            plt.plot(epoch_list[:len(valid_loss_list)], valid_loss_list, color=colors[i],
                     label='lr=' + str(lr) + 'drop=' + str(drop) + "--val")
            # best_model = torch.load('bestCNN_valid.pth')
            plt.plot(best_epoch, min(valid_loss_list), marker='o', color=colors[i], markersize=5)
            print('Learning rate: {}- Dropout: {} - lowest loss: {}'.format(lr, drop, min(valid_loss_list)))
            print('-' * 100)
            i += 1
    plt.legend(bbox_to_anchor=(1.04, 0.5), loc='center left')
    plt.title("Loss vs. Hyperparameters")
    plt.savefig("cnn_params.png")


lrs = [0.1, 0.01, 0.001]
dropouts = [0, 0.1, 0.2]
tuningParam(500, lrs, dropouts)
# best is 0.01, 0.2

"""# Testing

## Final CNN model
"""

transform_train = transforms.Compose([
    # image transformations chained by Compose
    transforms.ToTensor(),
    # changed to the computed mean/std 
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))
    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) 
])

transform_test = transforms.Compose([
    # image transformations chained by Compose
    transforms.ToTensor(),
    # changed to the computed mean/std 
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))
    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) 
])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform_train)

# DataLoader represents a Python iterable over a dataset, with support for automate batching etc.
trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=False,
                                          num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform_test)
testloader = torch.utils.data.DataLoader(testset, batch_size=128,
                                         shuffle=False, num_workers=2)

import numpy as np

cnn_min_loss = np.Inf
epochs_no_improve = 0  # a counter for the times that the epoch doesn't reduce the min loss


def test(epoch, lr, best_epoch, dropout=0, patience=20, stop=False):
    '''Evaluate the model, return the test acc and loss'''
    global cnn_best_acc  # refer to a global variable
    global cnn_min_loss, epochs_no_improve
    net.eval()  # switch to evaluation mode
    test_loss = 0
    batch_idx = 0
    correct = 0
    total = 0
    with torch.no_grad():  # with no_grad() we have higher speeds and can use larger batch size
        for batch_idx, (inputs, targets) in enumerate(testloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            loss = criterion(outputs, targets)

            test_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

    print('Test accuracy : %0.3f %%' % (100 * correct / total))

    # Save the model with the largest test acc
    acc = 100. * correct / total
    if acc > cnn_best_acc:
        print('Saving..')
        state = {
            'net': net.state_dict(),
            'acc': acc,
            'epoch': epoch,
            'lr': lr,
            'dropout': dropout,
        }
        torch.save(state, 'bestCNN.pth')
        cnn_best_acc = acc
    # Early stopping based on the loss
    # if the test loss is decreasing in 'patience' consecutive times, return the signal to break
    if test_loss < cnn_min_loss:
        epochs_no_improve = 0
        cnn_min_loss = test_loss
        best_epoch = epoch
    else:
        epochs_no_improve += 1
    if epochs_no_improve == patience:
        print('Early stopping!')
        stop = True

    return 100 * correct / total, test_loss / (batch_idx + 1), best_epoch, stop  # return the test acc for current model


# function to plot the acc vs epoch num
# cnn_best_acc = 0
def acc_epoch_plot(max_epoch, lr, dropout):
    # cnn_best_acc = 0
    global cnn_min_loss
    global epochs_no_improve
    cnn_min_loss = np.Inf
    epochs_no_improve = 0
    cnn_local_best = 0  # reset the single model's acc to 0 at the start
    epoch_list = list(range(1, max_epoch + 1))
    test_acc_list = []
    train_acc_list = []
    train_loss_list = []
    test_loss_list = []
    best_epoch = 0
    start = time.time()
    for epoch in epoch_list:  # train and validate the model until
        train_acc, train_loss = train(epoch)
        test_acc, test_loss, best_epoch, stop = test(epoch, lr=lr, best_epoch=best_epoch, dropout=dropout)
        test_acc_list.append(test_acc)
        train_acc_list.append(train_acc)
        train_loss_list.append(train_loss)
        test_loss_list.append(test_loss)
        if stop:  # if reach the patience limit, exit the loop
            break
    end = time.time()
    print('Time spent: %0.2f s' % (end - start))
    print('Learning rate: {}- Dropout: {} - lowest loss: {}'.format(lr, dropout, min(test_loss_list)))
    plt.figure(figsize=(12, 10))

    plt.subplot(211)
    plt.plot(epoch_list[:len(train_acc_list)], train_acc_list, label='train')
    plt.plot(epoch_list[:len(test_acc_list)], test_acc_list, label='test')
    # plt.plot(best_epoch, max(valid_loss_list), marker='o',  markersize=5)
    plt.legend()
    plt.title("Train & Test Accuracy vs. # of Epochs")
    plt.xlabel("Number of Epochs")
    plt.ylabel("Accuracy")

    plt.subplot(212)
    plt.plot(epoch_list[:len(train_loss_list)], train_loss_list, label='train')
    plt.plot(epoch_list[:len(test_loss_list)], test_loss_list, label='test')
    plt.plot(best_epoch, min(test_loss_list), marker='o', markersize=5)
    plt.legend()
    plt.title("Train & Test loss vs. # of Epochs")
    plt.xlabel("Number of Epochs")
    plt.ylabel("Loss")
    plt.savefig('train-val-acc-lr=' + str(lr) + 'drop=' + str(dropout) + '.png')
    plt.show()


net = ConvNet()
# Define a Loss function
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
cnn_best_acc = 0


def testing(lr, epoch, dropout=0):
    global net
    global optimizer
    net = ConvNet(dropout=dropout)
    net = net.to(device)
    if device == 'cuda':
        net = torch.nn.DataParallel(net)
        cudnn.benchmark = True
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)
    acc_epoch_plot(max_epoch=epoch, lr=lr, dropout=dropout)


testing(lr=0.001, epoch=250, dropout=0.2)

# print the best model by test acc
PATH = 'bestCNN.pth'
model = torch.load(PATH)
print('Test accuracy of the best CNN model with data augmentation is : %0.3f %% ' % (model['acc']))
print('Hyperparameters of the best CNN model are: Epoch = %d  learning rate = %f  dropout = %f' % (
model['epoch'], model['lr'], model['dropout']))

"""## Experiment on Data augmentation"""

transform_train = transforms.Compose([
    # image transformations chained by Compose
    # using data augmentation to make the model more robust
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    # changed to the computed mean/std 
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))
    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) 
])

transform_test = transforms.Compose([
    # image transformations chained by Compose
    transforms.ToTensor(),
    # changed to the computed mean/std 
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))
    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) 
])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform_train)

# DataLoader represents a Python iterable over a dataset, with support for automate batching etc.
trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=False,
                                          num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform_test)
testloader = torch.utils.data.DataLoader(testset, batch_size=128,
                                         shuffle=False, num_workers=2)

testing(lr=0.001, epoch=500, dropout=0.2, patience=20)

# print the best model by test acc
PATH = 'bestCNN.pth'
model = torch.load(PATH)
print('Test accuracy of the best CNN model with data augmentation is : %0.3f %% ' % (model['acc']))
print('Hyperparameters of the best CNN model are: Epoch = %d  learning rate = %f  dropout = %f' % (
model['epoch'], model['lr'], model['dropout']))

"""# Evaluation

## load net
"""

cnn = ConvNet()
state = torch.load('bestCNN.pth')['net']
cnn.load_state_dict(state)

class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs, 1)
        c = (predicted == labels).squeeze()
        for i in range(4):
            label = labels[i]
            class_correct[label] += c[i].item()
            class_total[label] += 1

for i in range(10):
    print('Accuracy of %5s : %2d %%' % (
        classes[i], 100 * class_correct[i] / class_total[i]))

"""## Classification Report and Confusion matrix"""


def convert_image(image):
    return image.reshape((image.shape[0], -1))


# Reshape image input
# For each image with shape (32,32,3), reshape it to a single row of length 32*32*3
trainset_array = next(iter(torch.utils.data.DataLoader(trainset, batch_size=len(trainset))))[0].numpy()
testset_array = next(iter(torch.utils.data.DataLoader(testset, batch_size=len(testset))))[0].numpy()
train_X_array, test_X_array = convert_image(trainset_array), convert_image(testset_array)

# Add a column of 1's as the bias term
train_X_design = np.concatenate((np.ones((train_X_array.shape[0], 1)), train_X_array), axis=1)
test_X_design = np.concatenate((np.ones((test_X_array.shape[0], 1)), test_X_array), axis=1)
# train_X_design.shape

train_y_array = np.asarray(trainset.targets)
test_y_array = np.asarray(testset.targets)
# train_y_array.shape

from torch.autograd import Variable


def cnn_predict():
    y_score = []  # predicted values for each instance
    y = []
    y_predicted = []
    for data in testloader:
        images, labels = data
        images, labels = images.to(device), labels.to(device)
        outputs = cnn(Variable(images.to(device)))
        _, predicted = torch.max(outputs.data, 1)
        c = (predicted == labels.to(device)).squeeze().cpu().numpy()
        y_score.append(outputs.data.cpu().detach().numpy())
        y_predicted.append(predicted.cpu())
        y.append(labels.cpu().numpy())
    # concatenate every mini-batch result as an nparray
    y = np.concatenate(y)
    y_score = np.concatenate(y_score)
    y_predicted = np.concatenate(y_predicted)
    # one-hot encode the label y
    N = y.shape[0]
    C = 10
    y_hot = np.zeros((N, C))
    y_hot[np.arange(N), y] = 1
    # return y_predicted without one-hot encoding, y_label with one hot encoding, y_score which is the raw output in (10000,10)
    return y_predicted, y_hot, y_score


from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
import time
import seaborn as sn


def plot_report(model, y_test, predictions):
    # classification report
    print(classification_report(y_true=y_test, y_pred=predictions, target_names=classes))
    # confusion matrix
    cm = confusion_matrix(y_true=y_test, y_pred=predictions, normalize='true')
    plt.figure(figsize=(10, 8))
    sn.heatmap(cm)
    plt.title(model)
    plt.savefig(str(model)[0:7] + '_cm.jpg')
    plt.show()


def evaluation(X_test, y_test):
    print("--------------------------------------------------------------------------------------")
    print("CNN with learning rate = 0.001  dropout = 0.20")
    cnnPredict, _, _ = cnn_predict()
    plot_report(cnn, y_test, cnnPredict)


evaluation(test_X_design, test_y_array)

"""## ROC"""

from torch.autograd import Variable

y_score = []
y = []
for data in testloader:
    images, labels = data
    outputs = net(Variable(images.to(device)))
    _, predicted = torch.max(outputs.data, 1)
    c = (predicted == labels.to(device)).squeeze().cpu().numpy()
    y_score.append(outputs.cpu().detach().numpy())
    y.append(labels.cpu().numpy())

y = np.concatenate(y)
y_score = np.concatenate(y_score)

N = y.shape[0]
C = 10
y_hot = np.zeros((N, C))
y_hot[np.arange(N), y] = 1

from sklearn.metrics import roc_curve, auc
from scipy import interp
import itertools
from itertools import cycle
import seaborn as sns

# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(10):
    fpr[i], tpr[i], _ = roc_curve(y_hot[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Compute micro-average ROC curve and ROC area
fpr["micro"], tpr["micro"], _ = roc_curve(y_hot.ravel(), y_score.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

# Compute macro-average ROC curve and ROC area
# First aggregate all false positive rates
all_fpr = np.unique(np.concatenate([fpr[i] for i in range(10)]))

# Then interpolate all ROC curves at this points
mean_tpr = np.zeros_like(all_fpr)
for i in range(10):
    mean_tpr += interp(all_fpr, fpr[i], tpr[i])

# Finally average it and compute AUC
mean_tpr /= 10

fpr["macro"] = all_fpr
tpr["macro"] = mean_tpr
roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])

# Plot of a ROC curve for a specific class
plt.figure(figsize=(11, 9))
lw = 2
plt.plot(fpr["macro"], tpr["macro"],
         label='macro-average ROC curve (area = {0:0.2f})'
               ''.format(roc_auc["macro"]),
         color='navy', linestyle='--', linewidth=4)
colors = sns.color_palette("Paired")
for i, color, j in zip(range(10), colors, classes):
    plt.plot(fpr[i], tpr[i], color=color, lw=lw,
             label='ROC curve of class {0} (area = {1:0.2f})'
                   ''.format(j, roc_auc[i]), linewidth=1.5)
plt.plot([0, 1], [0, 1], 'k--', lw=lw)
plt.xlim([0.0, 1.01])
plt.ylim([0.0, 1.01])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC&AUC')
plt.legend(loc="lower right")
plt.show()
